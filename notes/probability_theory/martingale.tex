\begin{definition}
    Let $(\Omega, \F, \P)$ be a probability space. A \textbf{stochastic process} 
    is a collection of random variables $X_t:\Omega\to (S, \S)$ where $t\in T$. 
    $T$ is a totally ordered index set. 
\end{definition}
\begin{remark}
    $T$ is often taken to be $\Z_+$ or $\R_+$, which represents the time. If 
    $T$ is countable, we say that $X_t$ is a \textbf{discrete time} process and 
    \textbf{continuous time} if $T$ is some uncountable subset of $\R$. 
\end{remark}

\begin{definition}
    A \textbf{filtration} $\set{\F_t}_{t\in T}$ is a collection of $\sigma$-algebras such that 
    $\F_t\subset\F_s$ for every $t<s$, $t,s\in T$.  
\end{definition}

\begin{definition}
    Let $X_t$ be a stochastic process and $\F_t$ be a filtration. We say that 
    $X_t$ is \textbf{adapted} to $\F_t$ or \textbf{$\F_t$-adapted} if $\sigma(X_t)\subset\F_t$ for all $t$. 
\end{definition}
\begin{remark}
    In many cases, the filtration is not mentioned since we may consider the 
    natural filtration generated by $X_t$ through the definition $\F_t = \sigma(\set{X_s|s\leq t})$. 
\end{remark}

\begin{definition}
    Let $X_t$ be a $\R$-valued stochastic process. We say that $X_t$ is an 
    \textbf{$\F_t$-martingale} if 
    \begin{thmenum}
        \item $\E\sbrc{\abs{X_t}}<\infty$. 
        \item $X_t$ is $\F_t$-adapted. 
        \item $X_t = \E\sbrc{X_s|\F_t}$ for all $s>t$. 
    \end{thmenum}
    We say that $X_t$ is a \textbf{supermartingale} if $X_t\geq \E\sbrc{X_s|\F_t}$ and 
    \textbf{submartungale} if $X_t\leq \E\sbrc{X_s|\F_t}$ for all $s>t$. 
\end{definition}
\begin{remark}
    $X_t$ is a martingale if and only if $X_t$ is both a submartingale and a supermartingale.
\end{remark}

\begin{proposition}
    Let $X_n$ be a discrete time stochastic process. 
    \begin{thmenum}
        \item If $X_n\geq \E\sbrc{X_{n+1}|\F_n}$ for all $n$, then $X_n$ is a supermartingale. 
        \item If $X_n\leq \E\sbrc{X_{n+1}|\F_n}$ for all $n$, then $X_n$ is a submartingale.
    \end{thmenum} 
\end{proposition}
\begin{proof}
    The proof for (b) is similar to (a). We prove only the case (a). Let $m>n$. 
    \begin{equation*}
        \E\sbrc{X_m|\F_n} = \E\sbrc{\E\sbrc{X_{m}|\F_{m-1}}|\F_n} 
        \geq \E\sbrc{X_{m-1}|\F_n} = \cdots \geq \E\sbrc{X_n|\F_n} = X_n.
    \end{equation*} 
    Hence $X_n$ is a supermartingale. 
\end{proof}

\begin{example}[Random Walk]
    Let $\xi_i\in\L^1$ be independent and identically distributed with $\E\sbrc{\xi_i} = 0$. 
    Set $X_0 = 0$ and $X_n = X_{n-1} + \xi_n$ for $n\in\N$. Clearly $X_n$ is 
    adapted to the natural filtration $\F_n$ generated by $X_n$ and 
    $\E\sbrc{\abs{X_n}}\leq n\E\sbrc{\abs{\xi_i}}<\infty$ for given $n$. Also, 
    \begin{equation*}
        \E\sbrc{X_{n+1}|\F_n} = \E\sbrc{X_n + \xi_{n+1}|\F_n} = X_n. 
    \end{equation*}
    Hence $X_n$ is a martingale. 
\end{example}

\begin{example}[Quadratic Martingale]
    Let $\xi_i$ be independent and identically distributed with $\E\sbrc{\xi_i} = 0$ 
    and $\E\sbrc{\xi_i^2} = \sigma^2<\infty$. Put $X_n = \sum_{i\leq n}\xi_i$. Then 
    $M_n = X_n^2 - n\sigma^2$ is a martingale. It is clear that $M_n$ is adapted 
    to the natural filtration $\F_n$ generated by $X_n$ and 
    \begin{equation*}
        \E\sbrc{\abs{M_n}} \leq \E\sbrc{X_n^2} + n\sigma^2 = 2n\sigma^2<\infty. 
    \end{equation*}
    Also, 
    \begin{equation*}
        \begin{split}
            \E\sbrc{M_{n+1}|\F_n} &= \E\sbrc{X_{n+1}^2-(n+1)\sigma^2|\F_n} 
            = \E\sbrc{X_n^2 + 2\xi_{n+1}X_n + \xi_{n+1}^2 - (n+1)\sigma^2|\F_n} \\ 
            &= X_n^2 + \sigma^2 - (n+1)\sigma^2 = M_n. 
        \end{split}
    \end{equation*}
    Hence $M_n$ is a martingale. 
\end{example}

\begin{example}[Exponential Martingale]
    Let $\xi_i$ be independent and identically distributed with $M(t) = \E\sbrc{\exp(t\xi_i)}<\infty$ 
    for given $t$. Put $X_i = \frac{\exp(t\xi_i)}{M(t)}$ and thus $\E\sbrc{X_i} = 1$. 
    Let $M_n = \prod_{i\leq n}X_i$. $M_n$ is adapted to the natural filtration $\F_n$ generated 
    by $X_n$ and 
    \begin{equation*}
        \E\sbrc{\abs{M_n}} = \E\sbrc{\prod_{i\leq n}X_i} = \prod_{i\leq n}\E\sbrc{X_i} = 1. 
    \end{equation*}
    Also, 
    \begin{equation*}
        \E\sbrc{M_{n+1}|\F_n} = M_n\E\sbrc{X_{n+1}|\F_n} = M_n\E\sbrc{X_{n+1}} = M_n. 
    \end{equation*}
    Hence $M_n$ is a martingale. 
\end{example}

\begin{lemma}
    Let $X_t$ be a $\F_t$-martingale and $\varphi$ is a function such that 
    $\E\sbrc{\abs{\varphi(X_t)}}<\infty$. 
    \begin{thmenum}
        \item If $\varphi$ is convex, then $\varphi(X_t)$ is a submartingale. 
        \item If $\varphi$ is concave, then $\varphi(X_t)$ is a supermartingale
    \end{thmenum}
\end{lemma}
\begin{proof}
    The proof for (b) is similar to (a). We only prove the case (a). Let $s>t$. 
    \begin{equation*}
        \E\sbrc{\varphi(X_s)|\F_t} \geq \varphi(\E\sbrc{X_s|\F_t}) = \varphi(X_t).
    \end{equation*}
    Hence $\varphi(X_t)$ is a submartingale. 
\end{proof}

\begin{lemma}
    Let $X_t$ be a stochastic process and $\varphi$ is a increasing function such that 
    $\E\sbrc{\abs{\varphi(X_t)}}<\infty$. 
    \begin{thmenum}
        \item If $X_t$ is a $\F_t$-submartingale and $\varphi$ is convex, then 
        $\varphi(X_t)$ is a $\F_t$-submartingale. 
        \item If $X_t$ is a $\F_t$-supermartingale and $\varphi$ is concave, then 
        $\varphi(X_t)$ is a $\F_t$-supermartingale.  
    \end{thmenum}
\end{lemma}
\begin{proof}
    For (a), let $s>t$. 
    \begin{equation*}
        \E\sbrc{\varphi(X_s)|\F_t} \geq \varphi(\E\sbrc{X_s|\F_t}) \geq \varphi(X_t).
    \end{equation*}
    Hence $\varphi(X_t)$ is a submartingale.

    For (b), 
    \begin{equation*}
        \E\sbrc{\varphi(X_s)|\F_t} \leq \varphi(\E\sbrc{X_s|\F_t}) \leq \varphi(X_t). 
    \end{equation*}
    Hence $\varphi(X_t)$ is a supermartingale.
\end{proof}

\begin{definition}
    Let $X_n$ be a stochastic process and $\F_n$ be the filtration generated by $X_n$. 
    A stochastic process $H_n$ is said to be \textbf{predictable} if $H_{n+1}$ is $\F_{n}$-adapted. 
\end{definition}

\begin{definition}
    Let $X_n$, $Y_n$ be two discrete-time stochastic processes. The \textbf{discrete-time 
    stochastic integral} is defined as 
    \begin{equation*}
        (X\cdot Y)_n = \sum_{i\leq n} X_i(Y_i - Y_{i-1}). 
    \end{equation*}
\end{definition}

\begin{theorem}\label{thm:no_arbitrage}
    If $X_n$ is a $\F_n$-supermartingale and $H_n\geq 0$ is predictable and is bounded 
    for each $n$. Then $(H\cdot X)_n$ is a supermartingale.  
\end{theorem}
\begin{proof}
    First, it is clear that $(H\cdot X)_n$ is $\F_n$-adapted since the discrete-time stochastic
    integral is a function of $(H_1,\ldots H_n,X_0,\ldots,X_n)$. Second, since $H_n$ is 
    bounded, say by $c_i$, 
    \begin{equation*}
        \E\sbrc{\abs{(H\cdot X)_n}} \leq \sum_{i\leq n}\E\sbrc{\abs{H_i}\abs{X_{i}-X_{i-1}}} 
        \leq \sum_{i\leq n}c_i\max_{1\leq i\leq n}2\E\sbrc{\abs{X_i}} < \infty
    \end{equation*}
    for given $n$ since $X_n$ is a supermartingale and satisfies that $X_n\in\L^1$. 
    Finally, 
    \begin{equation*}
        \begin{split}
            \E\sbrc{(H\cdot X)_{n+1}|\F_n} &= (H\cdot X)_n + \E\sbrc{H_{n+1}(X_{n+1}-X_n)|\F_n} \\ 
            &= (H\cdot X)_n + H_{n+1}\E\sbrc{X_{n+1}|\F_n} - H_{n+1}X_n \\ 
            &\leq (H\cdot X)_n + H_{n+1}X_n - H_{n+1}X_n = (H\cdot X)_n.
        \end{split}
    \end{equation*}
    Hence $(H\cdot X)_n$ is a supermartingale. 
\end{proof}
\begin{remark}
    If we instead assume that $X_n$ is a $\F_n$-submartingale, then $(H\cdot X)_n$ is a submartingale. 
    Furthermore, if $X_n$ is a $\F_n$-martingale, then for every predictable $H_n$, $(H\cdot X)_n$ is 
    a martingale. 
\end{remark}

\begin{definition}
    A random variable $\tau\in T$ is a \textbf{stopping time} if $\set{\tau\leq t}\in\F_t$. 
\end{definition}

\begin{example}[Hitting Time]
    Let $X_t$ be a stochastic process and $\F_t$ be the natural filtration generated by $X_t$. 
    The hitting time of $A$ is $\tau = \inf\Set{s\in T}{X_s\in A}$. Then $\tau$ is a stopping 
    time. 
\end{example}

\begin{proposition}
    Suppose that $\tau_1$ and $\tau_2$ are stopping times with respect to $\F_t$. 
    Then $\tau_1\wedge\tau_2$ and $\tau_1\vee\tau_2$ are stopping times. 
\end{proposition}
\begin{proof}
    Notice that 
    \begin{equation*}
        \set{\tau_1\wedge\tau_2\leq t} = \set{\tau_1\leq t}\cup\set{\tau_2\leq t}\in\F_t, 
        \quad\text{and}\quad 
        \set{\tau_1\vee\tau_2\leq t} = \set{\tau_1\leq t}\cap\set{\tau_2\leq t}\in\F_t.
    \end{equation*}
    Hence $\tau_1\wedge\tau_2$ and $\tau_1\vee\tau_2$ are stopping times. 
\end{proof}
\begin{remark}
    In particular, since any constant $n$ is also a stopping time, $n\wedge\tau$ is a 
    stopping time provided that $\tau$ is. The conclusion from \cref{thm:no_arbitrage} 
    also applies to the strategy of the form $H_n' = H_{n\wedge \tau}$.   
\end{remark}

\begin{theorem}[Martingale Convergence Theorem]
    
\end{theorem}